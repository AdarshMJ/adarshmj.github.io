<!DOCTYPE html>
<html>

  <head>
    <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Publications</title>
  <meta name="description" content="Publications.">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://0.0.0.0:4000/publications/">
  <link rel="alternate" type="application/rss+xml" title="Adarsh Jamadandi" href="http://0.0.0.0:4000/feed.xml">

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Baskervville:ital@0;1&family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">

</head>

    

    
  </head>

  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Adarsh Jamadandi</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
        
          
        
          
        
          
        
          
          <a class="page-link" href="/">About</a>
          
        
          
          <a class="page-link" href="/publications/">Publications</a>
          
        
          
          <a class="page-link" href="/outreach/">Outreach</a>
          
        
          
          <a class="page-link" href="/other_projects/">Miscellaneous</a>
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="post">
  <header class="post-header">
    <h1 class="post-title">Publications</h1>
  </header>

  <article class="post-content">
    <p>My research interests broadly encompass graph representation learning and geometric deep learning. Currently I am working on understanding and improving the generalization behavior of Graph Neural Networks. This includes studying phenomena like over-squashing, over-smoothing and understanding if, when and why GNNs memorize vs generalize. In the past I also have experience working on deep learning for computer vision applied to problems such as under-water image enhancement and anomaly detection in videos.</p>

    
    <div class="publications-list">
      
      <div class="publication-item">
        <div class="pub-row">
          <div class="pub-image">
            
              <img src="/assets/publications/ncmemo.jpg" alt="Memorization in Graph Neural Networks." class="pub-thumbnail">
            
          </div>
          
          <div class="pub-content">
            <h3 class="pub-title">Memorization in Graph Neural Networks.</h3>
            <p class="pub-authors">
              
                Adarsh Jamadandi*, 
              
                Jing Xu, 
              
                Adam Dziedzic, 
              
                Franziska Boenisch
              
            </p>
            <p class="pub-venue">
              <strong>arXiv pre-print</strong> (2025)
              
            </p>
            
            
            <div class="pub-abstract">
              <p>Do GNNs also memorize their training data? Why are only certain nodes memorized? How do you explain the emergence of memorization in GNNs? How to mitigate memorization in GNNs? We propose the first framework to analyze memorization in node classification. We find novel connections to graph homophily, implicit bias of GNNs and a novel metric to find nodes highly susceptible to memorization.</p>
            </div>
            
            
            <div class="pub-links">
              
                <a href="https://arxiv.org/abs/2508.19352" class="pub-link paper-link" target="_blank">
                  <i class="fas fa-file-pdf"></i> Paper
                </a>
              
              
                <a href="https://github.com/AdarshMJ/MemorizationinGNNs" class="pub-link code-link" target="_blank">
                  <i class="fab fa-github"></i> Code
                </a>
              
              
              
            </div>
            
            
          </div>
        </div>
      </div>
      
      <div class="publication-item">
        <div class="pub-row">
          <div class="pub-image">
            
              <img src="/assets/publications/comfyoverview.jpg" alt="GNNs Getting ComFy: Community and Feature Similarity Guided Rewiring." class="pub-thumbnail">
            
          </div>
          
          <div class="pub-content">
            <h3 class="pub-title">GNNs Getting ComFy: Community and Feature Similarity Guided Rewiring.</h3>
            <p class="pub-authors">
              
                Celia Rubio-Madrigal*, 
              
                Adarsh Jamadandi*, 
              
                Rebekka Burkholz
              
            </p>
            <p class="pub-venue">
              <strong>ICLR</strong> (2025)
              
                <span class="pub-note">*Equal contributions</span>
              
            </p>
            
            
            <div class="pub-abstract">
              <p>Graph rewiring methods have emerged as a powerful technique to address over-squashing and over-smoothing in Graph Neural Networks (GNNs). However, the underlying mechanisms that drive their effectiveness remain poorly understood. In this work, we investigate why spectral gap maximization works as a rewiring objective and under what conditions it may fail. We show that maximizing the spectral gap is not always beneficial and introduce a novel framework that leverages both community structure and feature similarity to guide graph rewiring.</p>
            </div>
            
            
            <div class="pub-links">
              
                <a href="https://arxiv.org/abs/2502.04891" class="pub-link paper-link" target="_blank">
                  <i class="fas fa-file-pdf"></i> Paper
                </a>
              
              
                <a href="https://github.com/RelationalML/ComFy" class="pub-link code-link" target="_blank">
                  <i class="fab fa-github"></i> Code
                </a>
              
              
                <button class="pub-link bibtex-link" onclick="toggleBibtex('2')">
                  <i class="fas fa-quote-left"></i> BibTeX
                </button>
              
              
            </div>
            
            
            <div class="bibtex-container" id="bibtex-2" style="display: none;">
              <pre class="bibtex-content">@inproceedings{rubio2025gnns,
  title={GNNs Getting ComFy: Community and Feature Similarity Guided Rewiring},
  author={Rubio-Madrigal, Celia and Jamadandi, Adarsh and Burkholz, Rebekka},
  booktitle={International Conference on Learning Representations},
  year={2025}
}
</pre>
              <button class="copy-bibtex" onclick="copyBibtex('2')">
                <i class="fas fa-copy"></i> Copy
              </button>
            </div>
            
          </div>
        </div>
      </div>
      
      <div class="publication-item">
        <div class="pub-row">
          <div class="pub-image">
            
              <img src="/assets/publications/spectralpruningoverview.jpg" alt="Spectral Pruning Against Over-Squashing and Over-Smoothing." class="pub-thumbnail">
            
          </div>
          
          <div class="pub-content">
            <h3 class="pub-title">Spectral Pruning Against Over-Squashing and Over-Smoothing.</h3>
            <p class="pub-authors">
              
                Adarsh Jamadandi*, 
              
                Celia Rubio-Madrigal*, 
              
                Rebekka Burkholz
              
            </p>
            <p class="pub-venue">
              <strong>NeurIPS</strong> (2024)
              
                <span class="pub-note">*Equal contributions</span>
              
            </p>
            
            
            <div class="pub-abstract">
              <p>We introduce the Braess Paradox in the context of Graph Neural Networks for the first time, showing that adding edges that maximize spectral gap can actually hurt performance. Building on this insight, we propose a novel spectral graph pruning strategy that simultaneously addresses over-squashing and over-smoothing. Our method not only improves GNN performance but also discovers graph lottery tickets - sparse subgraphs that maintain or exceed the performance of the full graph.</p>
            </div>
            
            
            <div class="pub-links">
              
                <a href="https://arxiv.org/abs/2404.04612" class="pub-link paper-link" target="_blank">
                  <i class="fas fa-file-pdf"></i> Paper
                </a>
              
              
                <a href="https://github.com/RelationalML/SpectralPruningBraess" class="pub-link code-link" target="_blank">
                  <i class="fab fa-github"></i> Code
                </a>
              
              
                <button class="pub-link bibtex-link" onclick="toggleBibtex('3')">
                  <i class="fas fa-quote-left"></i> BibTeX
                </button>
              
              
            </div>
            
            
            <div class="bibtex-container" id="bibtex-3" style="display: none;">
              <pre class="bibtex-content">@inproceedings{jamadandi2024spectral,
  title={Spectral Pruning Against Over-Squashing and Over-Smoothing},
  author={Jamadandi, Adarsh and Rubio-Madrigal, Celia and Burkholz, Rebekka},
  booktitle={Advances in Neural Information Processing Systems},
  year={2024}
}
</pre>
              <button class="copy-bibtex" onclick="copyBibtex('3')">
                <i class="fas fa-copy"></i> Copy
              </button>
            </div>
            
          </div>
        </div>
      </div>
      
      <div class="publication-item">
        <div class="pub-row">
          <div class="pub-image">
            
              <img src="/assets/publications/graphofthrones.jpg" alt="Graph of Thrones: Adversarial Perturbations dismantle Aristocracy in Graphs." class="pub-thumbnail">
            
          </div>
          
          <div class="pub-content">
            <h3 class="pub-title">Graph of Thrones: Adversarial Perturbations dismantle Aristocracy in Graphs.</h3>
            <p class="pub-authors">
              
                Adarsh Jamadandi, 
              
                Uma Mudenagudi
              
            </p>
            <p class="pub-venue">
              <strong>AAAI Student Poster, 2021.</strong> (2020)
              
            </p>
            
            
            <div class="pub-abstract">
              <p>We investigate how adversarial perturbations affect graph hyperbolicity. Hyperbolic embeddings have gained popularity for hierarchical graph data due to their geometric inductive biases, with models like Poincaré Ball and Hyperboloid being widely applied. Graph hyperbolicity indicates suitability for hyperbolic embedding—lower values enable distortion-free representations. We study adversarial perturbations that poison graph structure, making hyperbolic geometry ineffective for representation learning. To address this vulnerability, we propose using Lorentzian manifolds and empirically demonstrate their superior ability to capture hierarchical relationships under adversarial conditions. This is the first work exploring the relationship between adversarial attacks and hyperbolicity while providing a solution to mitigate such vulnerabilities.</p>
            </div>
            
            
            <div class="pub-links">
              
                <a href="https://aaai.org/papers/15801-dethroning-aristocracy-in-graphs-via-adversarial-perturbations-student-abstract/" class="pub-link paper-link" target="_blank">
                  <i class="fas fa-file-pdf"></i> Paper
                </a>
              
              
              
                <button class="pub-link bibtex-link" onclick="toggleBibtex('4')">
                  <i class="fas fa-quote-left"></i> BibTeX
                </button>
              
              
            </div>
            
            
            <div class="bibtex-container" id="bibtex-4" style="display: none;">
              <pre class="bibtex-content">@inproceedings{jamadandi2020graph,
  title={Graph of Thrones: Adversarial Perturbations dismantle Aristocracy in Graphs},
  author={Jamadandi, Adarsh and Mudenagudi, Uma},
  booktitle={AAAI Conference on Artificial Intelligence Student Abstract and Poster Program},
  year={2021}
}
</pre>
              <button class="copy-bibtex" onclick="copyBibtex('4')">
                <i class="fas fa-copy"></i> Copy
              </button>
            </div>
            
          </div>
        </div>
      </div>
      
      <div class="publication-item">
        <div class="pub-row">
          <div class="pub-image">
            
              <img src="/assets/publications/underwater.jpg" alt="Exemplar-based Underwater Image Enhancement Augmented by Wavelet Corrected Transforms." class="pub-thumbnail">
            
          </div>
          
          <div class="pub-content">
            <h3 class="pub-title">Exemplar-based Underwater Image Enhancement Augmented by Wavelet Corrected Transforms.</h3>
            <p class="pub-authors">
              
                Adarsh Jamadandi, 
              
                Uma Mudenagudi
              
            </p>
            <p class="pub-venue">
              <strong>Computer Vision and Pattern Recognition (CVPR Workshop, Oral)</strong> (2019)
              
            </p>
            
            
            <div class="pub-abstract">
              <p>We propose a novel deep learning framework for underwater image enhancement using wavelet-corrected transformations. Underwater images suffer from unique distortions due to wavelength-dependent light absorption (primarily red wavelengths) and scattering by suspended particles, resulting in greenish-blue hues and non-linear quality degradation. Our encoder-decoder architecture incorporates wavelet pooling and unpooling to perform progressive whitening and coloring transforms for realistic style transfer. We provide theoretical justification for why wavelet transforms excel at signal reconstruction and demonstrate state-of-the-art results on popular underwater datasets using SSIM, PSNR, and UCIQE metrics..</p>
            </div>
            
            
            <div class="pub-links">
              
                <a href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/AAMVEM/Jamadandi_Exemplar-based_Underwater_Image_Enhancement_Augmented_by_Wavelet_Corrected_Transforms_CVPRW_2019_paper.pdf" class="pub-link paper-link" target="_blank">
                  <i class="fas fa-file-pdf"></i> Paper
                </a>
              
              
              
                <button class="pub-link bibtex-link" onclick="toggleBibtex('5')">
                  <i class="fas fa-quote-left"></i> BibTeX
                </button>
              
              
            </div>
            
            
            <div class="bibtex-container" id="bibtex-5" style="display: none;">
              <pre class="bibtex-content">@InProceedings{Jamadandi_2019_CVPR_Workshops,
author = {Jamadandi, Adarsh and Mudenagudi, Uma},
title = {Exemplar-based Underwater Image Enhancement Augmented by Wavelet Corrected Transforms},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
month = {June},
year = {2019}
}
</pre>
              <button class="copy-bibtex" onclick="copyBibtex('5')">
                <i class="fas fa-copy"></i> Copy
              </button>
            </div>
            
          </div>
        </div>
      </div>
      
      <div class="publication-item">
        <div class="pub-row">
          <div class="pub-image">
            
              <img src="/assets/publications/videopred.gif" alt="PredGAN: A Deep Multi-Scale Video Prediction Framework for Detecting Anomalies in Videos." class="pub-thumbnail">
            
          </div>
          
          <div class="pub-content">
            <h3 class="pub-title">PredGAN: A Deep Multi-Scale Video Prediction Framework for Detecting Anomalies in Videos.</h3>
            <p class="pub-authors">
              
                Adarsh Jamadandi, 
              
                Sunidhi Kotturshettar, 
              
                Uma Mudenagudi
              
            </p>
            <p class="pub-venue">
              <strong>11th Indian Conference on Computer Vision, Graphics and Image Processing (ICVGIP '18)</strong> (2018)
              
            </p>
            
            
            <div class="pub-abstract">
              <p>In this paper we propose a multi-scale video prediction framework with adversarial training for detecting anomalies in videos. Anomalous events are those which do not conform to normal behavior. Supervised learning framework cannot account for all the unusual activities since a universal definition of anomaly cannot be adopted. To tackle this problem, we propose an unsupervised approach to learn the internal representation of videos and use this learning to accurately predict the future-frames of the videos. We train our network adversarially on videos consisting of only normal activities. When our network encounters unusual or irregular activities the generated frames consists of fuzzy regions where the irregular activities are present. These fuzzy regions consequently lower the peak signal to noise ratio (PSNR) of the generated frames. The PSNR values are normalized to have values between 0 and 1 and is used as a regularity score to tag a frame as anomalous or not-anomalous. We provide quantitative and qualitative evaluation of the proposed framework and also introduce Earth Mover's Distance as a new evaluation metric to assess the quality of the images generated. We demonstrate our framework on UCSD Pedestrian dataset and show that we achieve comparable results.</p>
            </div>
            
            
            <div class="pub-links">
              
                <a href="https://doi.org/10.1145/3293353.3293354" class="pub-link paper-link" target="_blank">
                  <i class="fas fa-file-pdf"></i> Paper
                </a>
              
              
              
                <button class="pub-link bibtex-link" onclick="toggleBibtex('6')">
                  <i class="fas fa-quote-left"></i> BibTeX
                </button>
              
              
            </div>
            
            
            <div class="bibtex-container" id="bibtex-6" style="display: none;">
              <pre class="bibtex-content">@inproceedings{10.1145/3293353.3293354,
author = {Jamadandi, Adarsh and Kotturshettar, Sunidhi and Mudenagudi, Uma},
title = {PredGAN: a deep multi-scale video prediction framework for detecting anomalies in videos},
year = {2020},
isbn = {9781450366151},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3293353.3293354},
doi = {10.1145/3293353.3293354},
abstract = {We propose a multi-scale video prediction framework with adversarial training for anomaly  detection in videos. Since supervised approaches cannot account for all unusual activities due to the lack of a universal anomaly definition, we use an unsupervised approach that learns video representations to predict future frames. Our network is trained adversarially on videos containing only normal activities. When encountering irregular activities, the network generates frames with fuzzy regions at anomalous locations, lowering the peak signal-to-noise ratio (PSNR). We normalize PSNR values to [0,1] as a regularity score for anomaly classification. We provide quantitative and qualitative evaluation, introduce Earth Mover's Distance as a new evaluation metric for generated image quality, and demonstrate comparable results on the UCSD Pedestrian dataset.},
booktitle = {Proceedings of the 11th Indian Conference on Computer Vision, Graphics and Image Processing},
articleno = {1},
numpages = {8},
keywords = {video frame prediction, generative adversarial networks, Anomaly detection},
location = {Hyderabad, India},
series = {ICVGIP '18}
}
</pre>
              <button class="copy-bibtex" onclick="copyBibtex('6')">
                <i class="fas fa-copy"></i> Copy
              </button>
            </div>
            
          </div>
        </div>
      </div>
      
    </div>
  </article>
</div>

<script>
function toggleBibtex(index) {
  const bibtexDiv = document.getElementById('bibtex-' + index);
  if (bibtexDiv.style.display === 'none') {
    bibtexDiv.style.display = 'block';
  } else {
    bibtexDiv.style.display = 'none';
  }
}

function copyBibtex(index) {
  const bibtexContent = document.querySelector('#bibtex-' + index + ' .bibtex-content').textContent;
  navigator.clipboard.writeText(bibtexContent).then(function() {
    // Show feedback
    const button = document.querySelector('#bibtex-' + index + ' .copy-bibtex');
    const originalText = button.innerHTML;
    button.innerHTML = '<i class="fas fa-check"></i> Copied!';
    setTimeout(() => {
      button.innerHTML = originalText;
    }, 2000);
  });
}
</script>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>Adarsh Jamadandi</li>
          <li><!-- Email Scrambler Component -->
<span class="email-scrambler" data-email="adarsh.jam@gmail.com">
  <span class="scrambled-email">adrsh.mjx@gml.cmo</span>
  <span class="reveal-hint">🥚 (Unscramble)</span>
</span>

<style>
.email-scrambler {
  cursor: pointer;
  display: inline-block;
  position: relative;
  font-family: monospace;
  background-color: #f8f9fa;
  padding: 0.2rem 0.4rem;
  border-radius: 3px;
  border: 1px solid #dee2e6;
  transition: all 0.3s ease;
}

.email-scrambler:hover {
  background-color: #e9ecef;
  transform: scale(1.02);
}

.email-scrambler.revealed {
  background-color: #d1ecf1;
  border-color: #bee5eb;
  color: #0c5460;
}

.scrambled-email {
  font-weight: 500;
  letter-spacing: 0.5px;
}

.reveal-hint {
  font-size: 0.7rem;
  color: #6c757d;
  margin-left: 0.3rem;
  font-style: italic;
  opacity: 0.7;
}

.email-scrambler.revealed .reveal-hint {
  display: none;
}

/* Click animation */
.email-scrambler:active {
  transform: scale(0.98);
}

/* Egg animation during unscrambling */
.email-scrambler.unscrambling .reveal-hint {
  animation: eggShake 0.1s infinite;
}

@keyframes eggShake {
  0%, 100% { transform: translateX(0px); }
  25% { transform: translateX(-3px); }
  75% { transform: translateX(3px); }
}
</style>

<script>
document.addEventListener('DOMContentLoaded', function() {
  const scramblers = document.querySelectorAll('.email-scrambler');
  
  scramblers.forEach(function(scrambler) {
    let isRevealed = false;
    const originalEmail = scrambler.dataset.email;
    const scrambledSpan = scrambler.querySelector('.scrambled-email');
    const originalScrambled = scrambledSpan.textContent;
    
    scrambler.addEventListener('click', function() {
      if (!isRevealed) {
        // Add unscrambling animation class
        scrambler.classList.add('unscrambling');
        
        // Reveal animation
        let steps = 0;
        const maxSteps = 8;
        
        const revealInterval = setInterval(function() {
          if (steps < maxSteps) {
            // Gradually reveal the real email
            const progress = steps / maxSteps;
            let tempEmail = '';
            
            for (let i = 0; i < originalEmail.length; i++) {
              if (Math.random() < progress) {
                tempEmail += originalEmail[i];
              } else {
                tempEmail += String.fromCharCode(97 + Math.floor(Math.random() * 26));
              }
            }
            
            scrambledSpan.textContent = tempEmail;
            steps++;
          } else {
            // Final reveal
            scrambledSpan.textContent = originalEmail;
            scrambler.classList.add('revealed');
            scrambler.classList.remove('unscrambling');
            isRevealed = true;
            clearInterval(revealInterval);
            
            // Make it clickable as mailto after reveal
            setTimeout(function() {
              scrambler.style.cursor = 'pointer';
              scrambler.onclick = function() {
                window.location.href = 'mailto:' + originalEmail;
              };
            }, 500);
          }
        }, 100);
      } else {
        // Already revealed, open email client
        window.location.href = 'mailto:' + originalEmail;
      }
    });
  });
});
</script>
</li>
          
        </ul>
      </div>
      <div class="footer-col footer-col-1">
        <ul class="social-media-list horizontal-icons">
          
          <li>
            <a href="https://github.com/adarshmj" title="GitHub Profile"><span class="icon icon--github"><svg viewBox="0 0 16 16" width="16" height="16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span></a>

          </li>
          
          
          <li>
            <a href="https://twitter.com/adarshjamadandi" title="Twitter Profile"><span class="icon icon--twitter"><svg viewBox="0 0 16 16" width="16" height="16"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span></a>

          </li>
          
          
          <li>
            <a href="https://www.linkedin.com/in/adarsh-jamadandi" title="LinkedIn Profile"><span class="icon icon--linkedin"><svg viewBox="0 0 24 24" width="16" height="16" fill="#828282">
  <path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/>
</svg>
</span></a>

          </li>
          
          
          <li>
            <a href="https://scholar.google.com/citations?user=dnA8qFkAAAAJ&hl" title="Google Scholar Profile"><span class="icon icon--google-scholar"><svg viewBox="0 0 24 24" width="16" height="16"><path fill="#828282" d="M5.242 13.769L0 9.5 12 0l12 9.5-5.242 4.269C17.548 11.249 14.978 9.5 12 9.5c-2.977 0-5.548 1.748-6.758 4.269zM12 10a7 7 0 1 0 0 14 7 7 0 0 0 0-14z"/></svg>
</span></a>

          </li>
          
        </ul>
      </div>
      <div class="footer-col footer-col-4">
        <!-- <p></p> -->
        <ul class="social-media-list">
        
        </ul>
      </div>
      
      
      
    </div>

  </div>

</footer>

  </body>

</html>
